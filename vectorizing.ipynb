{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b70d818d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\biswasshubendu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\biswasshubendu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from termcolor import colored\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "import re\n",
    "# Tutorial about Python regular expressions: https://pymotw.com/2/re/\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "import numpy as np \n",
    "import random\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from plotly import graph_objs as go\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "from collections import Counter\n",
    "\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import nltk\n",
    "import spacy\n",
    "import random\n",
    "from spacy.util import compounding\n",
    "from spacy.util import minibatch\n",
    "\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.stem.snowball import SnowballStemmer \n",
    "from nltk.tokenize import word_tokenize\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from tensorflow.python.keras.models import load_model\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, LSTM, Activation, Bidirectional,Embedding\n",
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import log_loss, confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_curve, auc , precision_score , classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "#from imblearn.over_sampling import SMOTE\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import math\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#from mlxtend.classifier import StackingClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.stats import stats\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "#from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from sklearn.metrics import log_loss,classification_report\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "#from sklearn.cross_validation import StratifiedKFold \n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import math\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#from mlxtend.classifier import StackingClassifier\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8c73c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93660864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Review</th>\n",
       "      <th>Components</th>\n",
       "      <th>Delivery and Customer Support</th>\n",
       "      <th>Design and Aesthetics</th>\n",
       "      <th>Dimensions</th>\n",
       "      <th>Features</th>\n",
       "      <th>Functionality</th>\n",
       "      <th>Installation</th>\n",
       "      <th>Material</th>\n",
       "      <th>Price</th>\n",
       "      <th>Quality</th>\n",
       "      <th>Usability</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>clean_review</th>\n",
       "      <th>temp_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>for some reason everybody complains and i'm co...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>reason everybody complains complaining toilet ...</td>\n",
       "      <td>['reason', 'everybody', 'complains', 'complain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>i like everything about it, great choice of sp...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>like everything great choice spray patterns pu...</td>\n",
       "      <td>['like', 'everything', 'great', 'choice', 'spr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>excellent ceiling fan brace. easy to install a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>excellent ceiling fan brace easy install well ...</td>\n",
       "      <td>['excellent', 'ceiling', 'fan', 'brace', 'easy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>work great easy to use . no issues at all with...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>work great easy use no issues hanging fan</td>\n",
       "      <td>['work', 'great', 'easy', 'use', 'no', 'issues...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>i would recommend this product because it is p...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>would recommend product perfect watering hangi...</td>\n",
       "      <td>['would', 'recommend', 'product', 'perfect', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6131</th>\n",
       "      <td>6131</td>\n",
       "      <td>easy to install. just be careful with the razo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>easy install careful razor trimming excess eas...</td>\n",
       "      <td>['easy', 'install', 'careful', 'razor', 'trimm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6132</th>\n",
       "      <td>6132</td>\n",
       "      <td>got a big pup and she had to learn about scree...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>got big pup learn screen doors fixed punctures...</td>\n",
       "      <td>['got', 'big', 'pup', 'learn', 'screen', 'door...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6133</th>\n",
       "      <td>6133</td>\n",
       "      <td>we installed our nest cam system a little over...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>installed nest cam system little month ago alr...</td>\n",
       "      <td>['installed', 'nest', 'cam', 'system', 'little...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6134</th>\n",
       "      <td>6134</td>\n",
       "      <td>this is a below average camera . the only thin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>average camera thing say decent comparison kam...</td>\n",
       "      <td>['average', 'camera', 'thing', 'say', 'decent'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6135</th>\n",
       "      <td>6135</td>\n",
       "      <td>so easy to install amd operate.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>easy install amd operate</td>\n",
       "      <td>['easy', 'install', 'amd', 'operate']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6136 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id                                             Review  Components  \\\n",
       "0        0  for some reason everybody complains and i'm co...           0   \n",
       "1        1  i like everything about it, great choice of sp...           0   \n",
       "2        2  excellent ceiling fan brace. easy to install a...           0   \n",
       "3        3  work great easy to use . no issues at all with...           0   \n",
       "4        4  i would recommend this product because it is p...           0   \n",
       "...    ...                                                ...         ...   \n",
       "6131  6131  easy to install. just be careful with the razo...           0   \n",
       "6132  6132  got a big pup and she had to learn about scree...           0   \n",
       "6133  6133  we installed our nest cam system a little over...           0   \n",
       "6134  6134  this is a below average camera . the only thin...           0   \n",
       "6135  6135                    so easy to install amd operate.           0   \n",
       "\n",
       "      Delivery and Customer Support  Design and Aesthetics  Dimensions  \\\n",
       "0                                 0                      0           0   \n",
       "1                                 0                      0           0   \n",
       "2                                 0                      0           0   \n",
       "3                                 0                      0           0   \n",
       "4                                 0                      0           0   \n",
       "...                             ...                    ...         ...   \n",
       "6131                              0                      0           0   \n",
       "6132                              0                      0           0   \n",
       "6133                              0                      0           0   \n",
       "6134                              0                      0           0   \n",
       "6135                              0                      0           0   \n",
       "\n",
       "      Features  Functionality  Installation  Material  Price  Quality  \\\n",
       "0            0              0             0         0      0        0   \n",
       "1            1              1             0         0      0        0   \n",
       "2            0              0             1         0      0        1   \n",
       "3            0              1             0         0      0        0   \n",
       "4            0              0             0         0      0        1   \n",
       "...        ...            ...           ...       ...    ...      ...   \n",
       "6131         0              0             1         0      0        0   \n",
       "6132         0              0             0         0      0        1   \n",
       "6133         0              0             0         0      0        1   \n",
       "6134         0              0             0         0      1        0   \n",
       "6135         0              0             1         0      0        0   \n",
       "\n",
       "      Usability  Polarity                                       clean_review  \\\n",
       "0             1         0  reason everybody complains complaining toilet ...   \n",
       "1             0         1  like everything great choice spray patterns pu...   \n",
       "2             0         1  excellent ceiling fan brace easy install well ...   \n",
       "3             1         1          work great easy use no issues hanging fan   \n",
       "4             0         1  would recommend product perfect watering hangi...   \n",
       "...         ...       ...                                                ...   \n",
       "6131          0         1  easy install careful razor trimming excess eas...   \n",
       "6132          1         1  got big pup learn screen doors fixed punctures...   \n",
       "6133          1         1  installed nest cam system little month ago alr...   \n",
       "6134          0         0  average camera thing say decent comparison kam...   \n",
       "6135          1         1                           easy install amd operate   \n",
       "\n",
       "                                              temp_list  \n",
       "0     ['reason', 'everybody', 'complains', 'complain...  \n",
       "1     ['like', 'everything', 'great', 'choice', 'spr...  \n",
       "2     ['excellent', 'ceiling', 'fan', 'brace', 'easy...  \n",
       "3     ['work', 'great', 'easy', 'use', 'no', 'issues...  \n",
       "4     ['would', 'recommend', 'product', 'perfect', '...  \n",
       "...                                                 ...  \n",
       "6131  ['easy', 'install', 'careful', 'razor', 'trimm...  \n",
       "6132  ['got', 'big', 'pup', 'learn', 'screen', 'door...  \n",
       "6133  ['installed', 'nest', 'cam', 'system', 'little...  \n",
       "6134  ['average', 'camera', 'thing', 'say', 'decent'...  \n",
       "6135              ['easy', 'install', 'amd', 'operate']  \n",
       "\n",
       "[6136 rows x 16 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('clean_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "87dcbee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## for word embedding\n",
    "import gensim\n",
    "import gensim.downloader as gensim_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "8eb07513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=-------------------------------------------------] 2.0% 34.1/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==------------------------------------------------] 4.7% 77.6/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[====----------------------------------------------] 10.0% 166.2/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[======--------------------------------------------] 12.0% 200.2/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=======-------------------------------------------] 14.2% 235.3/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========------------------------------------------] 16.2% 269.2/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=========-----------------------------------------] 18.7% 310.8/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==========----------------------------------------] 20.5% 341.5/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===========---------------------------------------] 23.0% 382.8/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[============--------------------------------------] 24.9% 414.2/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=============-------------------------------------] 26.9% 447.1/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==============------------------------------------] 28.9% 480.1/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===============-----------------------------------] 30.8% 511.4/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================---------------------------------] 34.2% 569.3/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================--------------------------------] 36.0% 599.1/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================--------------------------------] 37.5% 624.1/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===================-------------------------------] 39.4% 655.4/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[====================------------------------------] 41.4% 689.0/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=====================-----------------------------] 43.3% 720.4/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[======================----------------------------] 45.1% 750.3/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=======================---------------------------] 46.7% 777.1/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================--------------------------] 49.4% 821.7/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=========================-------------------------] 51.1% 850.3/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==========================------------------------] 52.9% 879.0/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===========================-----------------------] 54.8% 911.2/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[============================----------------------] 56.7% 942.5/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=============================---------------------] 59.3% 986.6/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==============================--------------------] 61.4% 1021.0/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===============================-------------------] 63.3% 1052.6/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[================================------------------] 65.3% 1085.5/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================================-----------------] 66.8% 1111.4/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[====================================--------------] 73.2% 1216.4/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=====================================-------------] 75.0% 1246.9/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[======================================------------] 77.1% 1282.4/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=======================================-----------] 80.0% 1329.4/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================----------] 81.9% 1361.2/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=========================================---------] 84.0% 1396.3/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===========================================-------] 87.9% 1461.0/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=============================================-----] 91.3% 1518.5/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==============================================----] 93.2% 1549.4/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===============================================---] 95.5% 1588.2/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[================================================--] 97.6% 1623.1/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================================================-] 99.7% 1657.0/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "nlp = gensim_api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3d95ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d65d93f",
   "metadata": {},
   "source": [
    "# Polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "160dbab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.155476302865316\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.85      0.78       261\n",
      "           1       0.97      0.92      0.94      1151\n",
      "\n",
      "    accuracy                           0.91      1412\n",
      "   macro avg       0.84      0.89      0.86      1412\n",
      "weighted avg       0.92      0.91      0.91      1412\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#splitting data into X and Y\n",
    "Y= df.Polarity\n",
    "X=df.clean_review\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, stratify = Y, test_size=0.23, random_state=42)# this is for time series split\n",
    "tf_idf_vect = TfidfVectorizer(ngram_range=(1,2))\n",
    "tf_idf_vect.fit(X_train)\n",
    "X_train_tfidf = tf_idf_vect.transform(X_train)\n",
    "X_test_tfidf = tf_idf_vect.transform(X_test)\n",
    "#fitting best model\n",
    "logmodel = LogisticRegression(C=10, penalty = 'l2' )\n",
    "logmodel.fit(X_train_tfidf, y_train)\n",
    "print(log_loss(logmodel.predict(X_test_tfidf),y_test))\n",
    "print(classification_report(logmodel.predict(X_test_tfidf),y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c0caf7b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'Review', 'Components', 'Delivery and Customer Support',\n",
       "       'Design and Aesthetics', 'Dimensions', 'Features', 'Functionality',\n",
       "       'Installation', 'Material', 'Price', 'Quality', 'Usability', 'Polarity',\n",
       "       'clean_review', 'temp_list'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0113d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4edc1b79",
   "metadata": {},
   "source": [
    "# Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "bd651083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5410694682207902\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98      1404\n",
      "           1       0.06      0.50      0.11         8\n",
      "\n",
      "    accuracy                           0.96      1412\n",
      "   macro avg       0.53      0.73      0.54      1412\n",
      "weighted avg       0.99      0.96      0.97      1412\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#splitting data into X and Y\n",
    "Y= df.Components\n",
    "X=df.clean_review\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, stratify = Y, test_size=0.23, random_state=42)# this is for time series split\n",
    "tf_idf_vect = TfidfVectorizer(ngram_range=(1,2))\n",
    "tf_idf_vect.fit(X_train)\n",
    "X_train_tfidf = tf_idf_vect.transform(X_train)\n",
    "X_test_tfidf = tf_idf_vect.transform(X_test)\n",
    "#fitting best model\n",
    "logmodel = LogisticRegression(C=10, penalty = 'l2' )\n",
    "logmodel.fit(X_train_tfidf, y_train)\n",
    "print(log_loss(logmodel.predict(X_test_tfidf),y_test))\n",
    "print(classification_report(logmodel.predict(X_test_tfidf),y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecebb98b",
   "metadata": {},
   "source": [
    "# Delivery and Customer Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "85350a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7338436825568184\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99      1401\n",
      "           1       0.27      1.00      0.42        11\n",
      "\n",
      "    accuracy                           0.98      1412\n",
      "   macro avg       0.63      0.99      0.71      1412\n",
      "weighted avg       0.99      0.98      0.98      1412\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#splitting data into X and Y\n",
    "Y= df['Delivery and Customer Support']\n",
    "X=df.clean_review\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, stratify = Y, test_size=0.23, random_state=42)# this is for time series split\n",
    "tf_idf_vect = TfidfVectorizer(ngram_range=(1,2))\n",
    "tf_idf_vect.fit(X_train)\n",
    "X_train_tfidf = tf_idf_vect.transform(X_train)\n",
    "X_test_tfidf = tf_idf_vect.transform(X_test)\n",
    "#fitting best model\n",
    "logmodel = LogisticRegression(C=10, penalty = 'l2' )\n",
    "logmodel.fit(X_train_tfidf, y_train)\n",
    "print(log_loss(logmodel.predict(X_test_tfidf),y_test))\n",
    "print(classification_report(logmodel.predict(X_test_tfidf),y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75c7f9a",
   "metadata": {},
   "source": [
    "# Design and Aesthetics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1afffdc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9324476690002392\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97      1315\n",
      "           1       0.56      0.87      0.68        97\n",
      "\n",
      "    accuracy                           0.94      1412\n",
      "   macro avg       0.77      0.91      0.82      1412\n",
      "weighted avg       0.96      0.94      0.95      1412\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#splitting data into X and Y\n",
    "Y= df['Design and Aesthetics']\n",
    "X=df.clean_review\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, stratify = Y, test_size=0.23, random_state=42)# this is for time series split\n",
    "tf_idf_vect = TfidfVectorizer(ngram_range=(1,2))\n",
    "tf_idf_vect.fit(X_train)\n",
    "X_train_tfidf = tf_idf_vect.transform(X_train)\n",
    "X_test_tfidf = tf_idf_vect.transform(X_test)\n",
    "#fitting best model\n",
    "logmodel = LogisticRegression(C=100, penalty = 'l2' )\n",
    "logmodel.fit(X_train_tfidf, y_train)\n",
    "print(log_loss(logmodel.predict(X_test_tfidf),y_test))\n",
    "print(classification_report(logmodel.predict(X_test_tfidf),y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18767da",
   "metadata": {},
   "source": [
    "# Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "4477fb62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.201526517373398\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.97      1326\n",
      "           1       0.49      0.91      0.63        86\n",
      "\n",
      "    accuracy                           0.94      1412\n",
      "   macro avg       0.74      0.92      0.80      1412\n",
      "weighted avg       0.96      0.94      0.94      1412\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#splitting data into X and Y\n",
    "Y= df['Dimensions']\n",
    "X=df.clean_review\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, stratify = Y, test_size=0.23, random_state=42)# this is for time series split\n",
    "tf_idf_vect = TfidfVectorizer(ngram_range=(1,2))\n",
    "tf_idf_vect.fit(X_train)\n",
    "X_train_tfidf = tf_idf_vect.transform(X_train)\n",
    "X_test_tfidf = tf_idf_vect.transform(X_test)\n",
    "#fitting best model\n",
    "logmodel = LogisticRegression(C=10, penalty = 'l2' )\n",
    "logmodel.fit(X_train_tfidf, y_train)\n",
    "print(log_loss(logmodel.predict(X_test_tfidf),y_test))\n",
    "print(classification_report(logmodel.predict(X_test_tfidf),y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca51ad78",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "be50affb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.663378447508322\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98      1406\n",
      "           1       0.07      0.83      0.13         6\n",
      "\n",
      "    accuracy                           0.95      1412\n",
      "   macro avg       0.53      0.89      0.55      1412\n",
      "weighted avg       1.00      0.95      0.97      1412\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#splitting data into X and Y\n",
    "Y= df['Features']\n",
    "X=df.clean_review\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, stratify = Y, test_size=0.23, random_state=42)# this is for time series split\n",
    "tf_idf_vect = TfidfVectorizer(ngram_range=(1,2))\n",
    "tf_idf_vect.fit(X_train)\n",
    "X_train_tfidf = tf_idf_vect.transform(X_train)\n",
    "X_test_tfidf = tf_idf_vect.transform(X_test)\n",
    "#fitting best model\n",
    "logmodel = LogisticRegression(C=10, penalty = 'l2' )\n",
    "logmodel.fit(X_train_tfidf, y_train)\n",
    "print(log_loss(logmodel.predict(X_test_tfidf),y_test))\n",
    "print(classification_report(logmodel.predict(X_test_tfidf),y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454274bc",
   "metadata": {},
   "source": [
    "# Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "aa8c78ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0390010596951\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.88       826\n",
      "           1       0.83      0.82      0.82       586\n",
      "\n",
      "    accuracy                           0.85      1412\n",
      "   macro avg       0.85      0.85      0.85      1412\n",
      "weighted avg       0.85      0.85      0.85      1412\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#splitting data into X and Y\n",
    "Y= df['Functionality']\n",
    "X=df.clean_review\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, stratify = Y, test_size=0.23, random_state=42)# this is for time series split\n",
    "tf_idf_vect = TfidfVectorizer(ngram_range=(1,2))\n",
    "tf_idf_vect.fit(X_train)\n",
    "X_train_tfidf = tf_idf_vect.transform(X_train)\n",
    "X_test_tfidf = tf_idf_vect.transform(X_test)\n",
    "#fitting best model\n",
    "logmodel = LogisticRegression(C=100, class_weight='balanced', penalty = 'l2' )\n",
    "logmodel.fit(X_train_tfidf, y_train)\n",
    "print(log_loss(logmodel.predict(X_test_tfidf),y_test))\n",
    "print(classification_report(logmodel.predict(X_test_tfidf),y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e9494b",
   "metadata": {},
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d29a7893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.027378890431018\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98      1271\n",
      "           1       0.78      0.97      0.87       141\n",
      "\n",
      "    accuracy                           0.97      1412\n",
      "   macro avg       0.89      0.97      0.93      1412\n",
      "weighted avg       0.98      0.97      0.97      1412\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#splitting data into X and Y\n",
    "Y= df['Installation']\n",
    "X=df.clean_review\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, stratify = Y, test_size=0.23,random_state=42)# this is for time series split\n",
    "tf_idf_vect = TfidfVectorizer(ngram_range=(1,2))\n",
    "tf_idf_vect.fit(X_train)\n",
    "X_train_tfidf = tf_idf_vect.transform(X_train)\n",
    "X_test_tfidf = tf_idf_vect.transform(X_test)\n",
    "#fitting best model\n",
    "logmodel = LogisticRegression(C=10, penalty = 'l2' )\n",
    "logmodel.fit(X_train_tfidf, y_train)\n",
    "print(log_loss(logmodel.predict(X_test_tfidf),y_test))\n",
    "print(classification_report(logmodel.predict(X_test_tfidf),y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6459ad19",
   "metadata": {},
   "source": [
    "# Material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "bd3f9d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.782766028440141\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99      1406\n",
      "           1       0.14      0.83      0.24         6\n",
      "\n",
      "    accuracy                           0.98      1412\n",
      "   macro avg       0.57      0.91      0.61      1412\n",
      "weighted avg       1.00      0.98      0.99      1412\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#splitting data into X and Y\n",
    "Y= df['Material']\n",
    "X=df.clean_review\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, stratify = Y, test_size=0.23,random_state=42)# this is for time series split\n",
    "tf_idf_vect = TfidfVectorizer(ngram_range=(1,2))\n",
    "tf_idf_vect.fit(X_train)\n",
    "X_train_tfidf = tf_idf_vect.transform(X_train)\n",
    "X_test_tfidf = tf_idf_vect.transform(X_test)\n",
    "#fitting best model\n",
    "logmodel = LogisticRegression(C=10, penalty = 'l2' )\n",
    "logmodel.fit(X_train_tfidf, y_train)\n",
    "print(log_loss(logmodel.predict(X_test_tfidf),y_test))\n",
    "print(classification_report(logmodel.predict(X_test_tfidf),y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54668f39",
   "metadata": {},
   "source": [
    "# Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "8e9d1cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3698381430499358\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98      1259\n",
      "           1       0.75      0.96      0.84       153\n",
      "\n",
      "    accuracy                           0.96      1412\n",
      "   macro avg       0.87      0.96      0.91      1412\n",
      "weighted avg       0.97      0.96      0.96      1412\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#splitting data into X and Y\n",
    "Y= df['Price']\n",
    "X=df.clean_review\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, stratify = Y, test_size=0.23,random_state=42)# this is for time series split\n",
    "tf_idf_vect = TfidfVectorizer(ngram_range=(1,2))\n",
    "tf_idf_vect.fit(X_train)\n",
    "X_train_tfidf = tf_idf_vect.transform(X_train)\n",
    "X_test_tfidf = tf_idf_vect.transform(X_test)\n",
    "#fitting best model\n",
    "logmodel = LogisticRegression(C=10, penalty = 'l2' )\n",
    "logmodel.fit(X_train_tfidf, y_train)\n",
    "print(log_loss(logmodel.predict(X_test_tfidf),y_test))\n",
    "print(classification_report(logmodel.predict(X_test_tfidf),y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e8ff6c",
   "metadata": {},
   "source": [
    "# Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "d486b7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "#lgb.LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "904baafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:42:18] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "4.280721403973989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.88      0.91       968\n",
      "           1       0.77      0.87      0.81       444\n",
      "\n",
      "    accuracy                           0.88      1412\n",
      "   macro avg       0.85      0.87      0.86      1412\n",
      "weighted avg       0.88      0.88      0.88      1412\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#splitting data into X and Y\n",
    "Y= df['Quality']\n",
    "X=df.clean_review\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, stratify = Y, test_size=0.23,random_state=42)# this is for time series split\n",
    "tf_idf_vect = TfidfVectorizer(ngram_range=(1,2))\n",
    "tf_idf_vect.fit(X_train)\n",
    "X_train_tfidf = tf_idf_vect.transform(X_train)\n",
    "X_test_tfidf = tf_idf_vect.transform(X_test)\n",
    "#fitting best model\n",
    "logmodel = XGBClassifier()\n",
    "logmodel.fit(X_train_tfidf, y_train)\n",
    "print(log_loss(logmodel.predict(X_test_tfidf),y_test))\n",
    "print(classification_report(logmodel.predict(X_test_tfidf),y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5a2ac3",
   "metadata": {},
   "source": [
    "# Usability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "23f38182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5195186510357703\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.96      1192\n",
      "           1       0.71      0.91      0.80       220\n",
      "\n",
      "    accuracy                           0.93      1412\n",
      "   macro avg       0.84      0.92      0.88      1412\n",
      "weighted avg       0.94      0.93      0.93      1412\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#splitting data into X and Y\n",
    "Y= df['Usability']\n",
    "X=df.clean_review\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, stratify = Y, test_size=0.23,random_state=42)# this is for time series split\n",
    "tf_idf_vect = TfidfVectorizer(ngram_range=(1,2))\n",
    "tf_idf_vect.fit(X_train)\n",
    "X_train_tfidf = tf_idf_vect.transform(X_train)\n",
    "X_test_tfidf = tf_idf_vect.transform(X_test)\n",
    "#fitting best model\n",
    "logmodel = LogisticRegression(C=10,penalty = 'l2' )\n",
    "logmodel.fit(X_train_tfidf, y_train)\n",
    "print(log_loss(logmodel.predict(X_test_tfidf),y_test))\n",
    "print(classification_report(logmodel.predict(X_test_tfidf),y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b087a1cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "783fa307",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "49714d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# model = LogisticRegression()\n",
    "# penalty = ['l2']\n",
    "# class_weight = ['balanced']\n",
    "# c_values = [100, 10, 1.0, 0.1, 0.01]\n",
    "# # define grid search\n",
    "# grid = dict(solver=solvers,penalty=penalty,C=c_values,class_weight=class_weight)\n",
    "\n",
    "\n",
    "# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='roc_auc')\n",
    "# grid_result = grid_search.fit(X_train_scale, y_train)\n",
    "# # summarize results\n",
    "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "# means = grid_result.cv_results_['mean_test_score']\n",
    "# stds = grid_result.cv_results_['std_test_score']\n",
    "# params = grid_result.cv_results_['params']\n",
    "# for mean, stdev, param in zip(means, stds, params):\n",
    "#     print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a08802c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "39ce12a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['explained_variance', 'r2', 'max_error', 'neg_median_absolute_error', 'neg_mean_absolute_error', 'neg_mean_absolute_percentage_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'neg_root_mean_squared_error', 'neg_mean_poisson_deviance', 'neg_mean_gamma_deviance', 'accuracy', 'top_k_accuracy', 'roc_auc', 'roc_auc_ovr', 'roc_auc_ovo', 'roc_auc_ovr_weighted', 'roc_auc_ovo_weighted', 'balanced_accuracy', 'average_precision', 'neg_log_loss', 'neg_brier_score', 'adjusted_rand_score', 'rand_score', 'homogeneity_score', 'completeness_score', 'v_measure_score', 'mutual_info_score', 'adjusted_mutual_info_score', 'normalized_mutual_info_score', 'fowlkes_mallows_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'jaccard', 'jaccard_macro', 'jaccard_micro', 'jaccard_samples', 'jaccard_weighted'])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.metrics.SCORERS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "129d2f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.01, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'newton-cg'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "99c21761",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "66d3b531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6691867007047034"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f6d137ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.75      0.78       341\n",
      "           1       0.92      0.94      0.93      1071\n",
      "\n",
      "    accuracy                           0.90      1412\n",
      "   macro avg       0.87      0.85      0.86      1412\n",
      "weighted avg       0.90      0.90      0.90      1412\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dd92b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
